---
title: "1.4 clean"
author: "Greta Lotz"
date: "2023-12-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, warning=FALSE, include=}
library(tidyverse)
library(knitr)
library(scales)
library(gt)
library(gtExtras)
library(haven)

```

```{r warning=FALSE}

df_survey <- readRDS("survey/meof_usa_survey_df.rds")
df_survey <- zap_labels(df_survey)

## Cleaning
# Drop observations where vig_1_hateful is missing
df_survey <- df_survey[!is.na(df_survey$vig_1_hateful), ]

# Recoding the vig_(x)_topic variable

#print(df_survey$vig_1_topic)

# Vector with recoding rules for loop
recoding_rules <- c("gender" = "Women",
                    "ideologydems" = "Democrats",
                    "ideologyreps" = "Republicans",
                    "muslim" = "Muslim immigrants")

# Loop through the variables and apply the recoding rules
for (var_suffix in 1:8) {
  var_name <- paste0("vig_", var_suffix, "_topic")
  df_survey <- df_survey %>%
    mutate_at(vars(starts_with(var_name)), funs(recode(., !!!recoding_rules)))
}

#print(df_survey$vig_1_topic)

# Combine variables _topic and _sender_message 1-8 into 8 new variables with the full string

#print(df_survey$vig_1_sender_message)
# First, clean up the string "Women should be caring mothers and not pursue \r\na selfish career." 

# Loop through the variables and process the sender messages
for (var_suffix in 1:8) {
  sender_message_var <- paste0("vig_", var_suffix, "_sender_message")
  df_survey[[sender_message_var]] <- gsub("[\r\n\t]", " ", df_survey[[sender_message_var]])
  df_survey[[sender_message_var]] <- gsub("\\s+", " ", df_survey[[sender_message_var]])
}

#print(df_survey$vig_8_sender_message)


# Construct full message for vig_1

# Test for one
# df_survey <- df_survey %>%
# mutate(full_message_vig_1 = paste(vig_1_topic, vig_1_sender_message, sep = " "))
#print(df_survey$full_message_vig_1)

# Loop through the variables and create new columns
for (var_suffix in 1:8) {
  topic_var <- paste0("vig_", var_suffix, "_topic")
  message_var <- paste0("vig_", var_suffix, "_sender_message")
  new_column_name <- paste0("full_message_vig_", var_suffix)
  
  df_survey <- df_survey %>%
    mutate(!!new_column_name := paste(.data[[topic_var]], .data[[message_var]], sep = " "))
}

# Display the new columns to verify
#new_column_names <- grep("^full_message_vig_", names(df_survey), value = TRUE)
#print(df_survey[, new_column_names, drop = FALSE])

# Create a subset with the relevant variables (optional, for my own improved workflow)
# Extract the columns for each x in the range 1 to 8
selected_columns <- c("personid", 
                      paste0("vig_", 1:8, "_hateful"), 
                      paste0("full_message_vig_", 1:8))
df_subset <- df_survey[selected_columns]

#df_subset
```

```{r warning=FALSE}
## In this next part I switch to long format, separate the df into subsets according to each message and calculate the mean rating and standard devialtion

# Create a data frame with unique message texts
unique_messages <- data.frame(
  message_id = seq_along(unique(unlist(df_subset[, grep("^full_message_vig_", names(df_subset))]))),
  message = unique(unlist(df_subset[, grep("^full_message_vig_", names(df_subset))]))
)

##Transform into long format
# Specify the column names for pivoting
cols_to_long <- c(paste0("full_message_vig_", 1:8), paste0("vig_", 1:8, "_hateful"))

# Use pivot_longer to transform the data frame to long format
df_subset_long <- pivot_longer(df_subset, cols = cols_to_long, 
                        names_to = c(".value", "vig_num"), 
                        names_pattern = "(\\w+)_([0-9]+)")

# Rename the columns
colnames(df_subset_long) <- c("personid", "vig_num", "full_message", "rating_hateful")

## Create tibbles for each individual message
# Create an empty list to store results
result_list <- list()

# Loop through each unique message
for (target_message in unique_messages$message) {
  # Create a subset for the target message
  subset_target_message <- df_subset_long %>%
    filter(full_message == target_message) %>%
    left_join(unique_messages, by = c("full_message" = "message")) %>%
    select(message_id, personid, full_message, rating_hateful)
  # Calculate mean and standard deviation for the hatefulness ratings in the subset
  subset_target_message <- subset_target_message %>%
    mutate(
      mean_hatefulness = mean(rating_hateful, na.rm = TRUE),
      sd_hatefulness = sd(rating_hateful, na.rm = TRUE)
    )
  
  # Add the result to the list
  result_list[[target_message]] <- subset_target_message
}
#result_list

# This next part might have been possible in one step with the previous loop but I did not get that to run
# Create a copy of the original result_list 
result_list_updated <- lapply(result_list, function(current_table) {
  # Count the occurrences of each rating
  rating_counts <- table(current_table$rating_hateful)
  
  # Create new columns with counts for each rating
  for (i in 1:5) {
    col_name <- paste0("total_rating_", i)
    current_table[col_name] <- rating_counts[as.character(i)]
  }
  return(current_table)
})

#result_list_updated
```

```{r Test NA, eval=FALSE, include=FALSE}
# Test if NAs can be true
result <- df_subset_long %>%
  filter(rating_hateful == 5, full_message == "Women should be a caring mother and not pursue a selfish career.") %>%
  summarise(count = n())

# Access the count value
count_value <- result$count

count_value
```

```{r warning=FALSE}
# Combine all results of individual tibbles into one data frame
result_table <- bind_rows(result_list_updated, .id = "message") %>%
  group_by(message) %>%
  filter(row_number() == 1) %>%
  ungroup() %>%
  mutate_all(~replace(., is.na(.), 0)) %>% # set NA to 0
  select(message_id, message, mean_hatefulness, sd_hatefulness, total_rating_1, total_rating_2, total_rating_3, total_rating_4, total_rating_5)

#result_table

## Merge df_subset_long and result_table so I can visualize the frequency of ratings based on the messages column in the gt table after

merged_data <- merge(df_subset_long, result_table, by.x = "full_message", by.y = "message", all.x = TRUE)

# Select the columns to keep for gt table
selected_columns <- c("personid","full_message", "rating_hateful", "mean_hatefulness", "sd_hatefulness", "message_id")
df_merged_long <- merged_data[selected_columns]

#df_merged_long
```

```{r warning=FALSE}
## Table 

# For a reference to a foot note
superscript_1 = "\u00B9"

# gt table
gt_tab <- df_merged_long %>%
  group_by(full_message) %>%
  summarize(
    percentage_data = list(rating_hateful),
    mean_hatefulness = sprintf("%.2f", first(as.numeric(mean_hatefulness))),
    sd_hatefulness = sprintf("%.2f", first(sd_hatefulness)),
    .groups = "drop"
  ) %>%
  rename(
   "Message" = full_message,
    "Rating (%)" = percentage_data,
   "Average Rating" = mean_hatefulness,
    "Standard Deviation" = sd_hatefulness
  )%>%
  arrange(
    case_when(
      grepl("^Democrats", Message) ~ 1,
      grepl("^Republicans", Message) ~ 2,
      grepl("^Muslim immigrants", Message) ~ 3,
      grepl("^Women", Message) ~ 4
    ),
    desc(`Average Rating`)  # Order by Average Rating in descending order
  ) %>%
 gt()  %>%
  gt_theme_espn() %>%
  tab_header(
    title = "Perceived Hate of Social Media Messages", 
    subtitle = paste("Each respondent (a US sample of n= 1220) evaluated eight distinct messages with answers ranging from 1 - 'Not hateful at all' to 5-", " 'Extremely hateful", superscript_1, "\n")
  ) %>%
  tab_spanner(
    label = "1|2|3|4|5",
    columns = 'Rating (%)'
  ) %>%
  tab_stubhead(
    label = "Messages"
  ) %>%
  gt_plt_dist(
    "Rating (%)",
    type = "histogram",
    fig_dim = c(10, 30),
    line_color = "black",
    fill_color = "grey",
    bw = 1
  ) %>%
  tab_source_note(md("1 Full range of answers: 1-Not hateful at all; 2-Not very hateful; 3-Somewhat hateful; 4-Very hateful; 5- Extremely hateful 
    \n Data source: The Media Exposure and Opinion Formation (MEOF) study - USA. 
    \n The vignette experiment was conducted in 2019.")) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightblue", alpha = 0.2) 
    ),
    locations = cells_body(rows = grepl("^Democrats", Message))
  )%>%
  tab_style(
    style = list(
      cell_fill(color = "#FFC0CB", alpha = 0.2) 
    ),
    locations = cells_body(rows = grepl("^Republicans", Message))
  )%>%
  tab_style(
    style = list(
      cell_fill(color = "#E6E6FA", alpha = 0.2) 
    ),
    locations = cells_body(rows = grepl("^Muslim immigrants", Message))
  )%>%
  tab_style(
    style = list(
      cell_fill(color = "#FFFAA0", alpha = 0.2) 
    ),
    locations = cells_body(rows = grepl("^Women", Message))
  )%>%
data_color(
    columns = `Average Rating`,
    target_columns = `Average Rating`,
    palette = c("blue", "orange") # a bit unusual when used to a green to red gradient but this is color blind friendly and since it is ordered according to value, it alleviates some of the importance of the color while still offering good comparability in the most extreme values per group. Just through this, a color blind person should be able to see when a new group starts as well, since I am aware the light row shading is not accessible for all.
  )

gt_tab


## A comment on the similar messages: I went back and forth about combining the similar sentences (...are stupid animals./ ...are a stupid animal. and ...a caring mother/ caring mothers) into one but ended up deciding against it. These are the same messages as in the guide and there is no more information why they are so similar. I notices the ones with the wrong grammar where taken less seriously, since they have a slightly less high average rating. This also played into me not wanting to combine them. 
```

